{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d112d4",
   "metadata": {},
   "source": [
    "# Quickstart: Using the Prioritised Flat Buffer with Flashbax\n",
    "\n",
    "This guide demonstrates how to use the Prioritised Flat Buffer for experience replay in reinforcement learning tasks. The Prioritised Flat Buffer operates like a uniform flat buffer however it returns batches of sampled experience according to given priorities. This is akin to the buffer used in the [PER paper](https://arxiv.org/abs/1511.05952) by Schaul et al. (2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a0f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running locally as a dev then uncomment the below 2 lines. \n",
    "# import sys\n",
    "# sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfdaeb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chex\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Setup fake devices - we use this later with `jax.pmap`.\n",
    "DEVICE_COUNT_MOCK = 2\n",
    "chex.set_n_cpu_devices(DEVICE_COUNT_MOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5122ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import flashbax as fbx\n",
    "except ModuleNotFoundError:\n",
    "    print('installing flashbax')\n",
    "    %pip install -q flashbax\n",
    "    import flashbax as fbx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43592d",
   "metadata": {},
   "source": [
    "# Prioritised buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0281f0de",
   "metadata": {},
   "source": [
    "The prioritised buffer allows for experience to be saved to the buffer with a \"priority\" that determines how likely it is to be sampled. This is based on the paper [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952) by Schaul et al. (2015).\n",
    "The prioritised buffer has the following key functionality:\n",
    "- **init**: initialise the state of the buffer\n",
    "- **add**: add a new batch of experience data to the buffer's state\n",
    "- **can_sample**: check if the buffer's state is full enough to be sampled from\n",
    "- **sample**: sample a batch from the buffer's state with probability proportional to the samples priority\n",
    "- **set_priorities**: update the priorities of specific experience within the buffer state\n",
    "\n",
    "below we will go through how each of these can be used. In the below code we use these functions without `jax.pmap`, however they can be easily adapted for this. To see how this can be done we refer to the `examples/quickstart_flat_buffer` notebook and the `test_prioritised_buffer_does_not_smoke` function notebook in `flashbax.buffers.prioritised_buffer_test.py`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a48a7",
   "metadata": {},
   "source": [
    "Firstly, we provide the function `make_prioritised_flat_buffer` which returns an instance of the `PrioritisedTrajectoryBuffer` with wrapped sample and add functionality. This is a `Dataclass` containing the aforementioned `init`, `add`, `can_sample`, `sample` and `set_prioritised` pure functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e20e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e.toledo/flashbax/flashbax/buffers/trajectory_buffer.py:473: UserWarning: Setting max_size dynamically sets the `max_length_time_axis` to be `max_size`//`add_batch_size = 5`.This allows one to control exactly how many transitions are stored in the buffer.Note that this overrides the `max_length_time_axis` argument.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# First define hyper-parameters of the buffer.\n",
    "max_length = 32 # Maximum length of buffer (max number of experiences stored within the state).\n",
    "min_length = 8 # Minimum number of experiences saved in the buffer state before we can sample.\n",
    "sample_batch_size = 4 # Batch size of experience data sampled from the buffer.\n",
    "# The buffer will be sampled from with probability proportional to priority**priority_exponent.\n",
    "priority_exponent = 0.6\n",
    "\n",
    "add_sequences = False # Will we be adding data in sequences to the buffer?\n",
    "add_batch_size = 6    # Will we be adding data in batches to the buffer? \n",
    "                      # It is possible to add data in both sequences and batches. \n",
    "                      # If adding data in batches, what is the batch size that is being added each time?\n",
    "\n",
    "# Instantiate the prioritised buffer, which is a NamedTuple of pure functions.\n",
    "buffer = fbx.make_prioritised_flat_buffer(\n",
    "    max_length, min_length, sample_batch_size, add_sequences, add_batch_size, priority_exponent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f76568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1695739455.593782 1496431 pjrt_api.cc:98] GetPjrtApi was found for tpu at /home/e.toledo/miniconda3/envs/flashbax/lib/python3.10/site-packages/libtpu/libtpu.so\n",
      "I0000 00:00:1695739455.593878 1496431 pjrt_api.cc:67] PJRT_Api is set for device type tpu\n",
      "I0000 00:00:1695739455.593882 1496431 pjrt_api.cc:72] PJRT plugin for tpu has PJRT API version 0.30. The framework PJRT API version is 0.30.\n",
      "I0000 00:00:1695739458.615064 1496431 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n",
      "/home/e.toledo/miniconda3/envs/flashbax/lib/python3.10/site-packages/jax/_src/linear_util.py:190: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  ans = self.f(*args, **dict(self.params, **kwargs))\n"
     ]
    }
   ],
   "source": [
    "rng_key = jax.random.PRNGKey(0) # Setup source of randomness\n",
    "\n",
    "# Initialise the buffer's state using the `init` function. \n",
    "# To do this we need a unit of experience data which is used to infer \n",
    "# the tree stucture of the experience that will be added later to the buffer state.\n",
    "# We create a fake timestep for the example.\n",
    "fake_timestep = {\"obs\": jnp.array([5, 4]), \"reward\": jnp.array(1.0)} \n",
    "state = buffer.init(fake_timestep)\n",
    "\n",
    "# Now fill the buffer above its minimum length using the `add` function.\n",
    "# The add function expects batches of experience - we create a fake batch by stacking\n",
    "# timesteps.\n",
    "# New samples to the buffer have their priority set to the maximum priority within the buffer. \n",
    "fake_batch = jax.tree.map(lambda x: jnp.stack([x + i for i in range(add_batch_size)]),\n",
    "                          fake_timestep) \n",
    "state = buffer.add(state, fake_batch)\n",
    "assert buffer.can_sample(state) == False  # After one batch the buffer is not yet full.\n",
    "state = buffer.add(state, fake_batch)\n",
    "assert buffer.can_sample(state)  # Now the buffer is full. \n",
    "\n",
    "\n",
    "# Sample from the buffer. This returns a batch of `PrioritisedTransitionSample` which is a Dataclass \n",
    "# With the fields `experience`, `indices` and `priorities`. The `experience` field contains an experience \n",
    "# pair giving the transition data which has the same structure as \n",
    "# `fake_timestep`, but with an additional leading batch dimension.\n",
    "rng_key, rng_subkey = jax.random.split(rng_key)\n",
    "batch = buffer.sample(state, rng_subkey)\n",
    "\n",
    "\n",
    "# Adjust priorities.This would commonly be set to the abs(td_error) of the corresponding sample. \n",
    "new_priorities = jnp.ones_like(batch.priorities) + 10007 # Fake new priorities\n",
    "state = buffer.set_priorities(state, batch.indices, new_priorities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0b67e",
   "metadata": {},
   "source": [
    "To understand the specifics of how the prioritised buffer works we recommend inspecting the above objects returned from each of the key buffer functions, while looking at the code and documentation in the `flashbax.buffer.prioritised_buffer.py` file. For example, by inspecting the `batch` we see that it is a NamedTuple \n",
    "with the fields `experience`, `indices` and `priorities`. The `experience` field returns a `TransitionPair` which has `first` and `second` attributes with the same structure as `fake_timestep`, but with an additional leading batch dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61db64a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['experience', 'indices', 'priorities'])\n",
      "indices: [ 0  5 15 20]\n",
      "priorities: [1. 1. 1. 1.]\n",
      "experience keys: dict_keys(['obs', 'reward'])\n",
      "experience keys: dict_keys(['obs', 'reward'])\n",
      "obs shape: (4, 2)\n"
     ]
    }
   ],
   "source": [
    "print(batch.__dict__.keys())\n",
    "print(f\"indices: {batch.indices}\")\n",
    "print(f\"priorities: {batch.priorities}\") \n",
    "print(f\"experience keys: {batch.experience.first.keys()}\")\n",
    "print(f\"experience keys: {batch.experience.second.keys()}\")\n",
    "print(f\"obs shape: {batch.experience.first['obs'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169265d2",
   "metadata": {},
   "source": [
    "The above batch was sampled before we adjusted the priorities, if we sample again we see that the samples priorities now match the adjusted priorities (the adjusted priorities we set have a very high priority so we are basically guaranteed to sample these experiences). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10eb27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['experience', 'indices', 'priorities'])\n",
      "indices: [ 0  5 15 20]\n",
      "priorities: [251.30885 251.30885 251.30885 251.30885] == new_priorities**priority_exponent == 251.30885314941406\n",
      "experience keys: dict_keys(['obs', 'reward'])\n",
      "experience keys: dict_keys(['obs', 'reward'])\n",
      "obs shape: (4, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e.toledo/miniconda3/envs/flashbax/lib/python3.10/site-packages/jax/_src/linear_util.py:190: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  ans = self.f(*args, **dict(self.params, **kwargs))\n"
     ]
    }
   ],
   "source": [
    "rng_key, rng_subkey = jax.random.split(rng_key)\n",
    "batch = buffer.sample(state, rng_subkey)\n",
    "print(batch.__dict__.keys())\n",
    "print(f\"indices: {batch.indices}\")\n",
    "print(f\"priorities: {batch.priorities} == new_priorities**priority_exponent == {new_priorities[0]**priority_exponent}\")\n",
    "print(f\"experience keys: {batch.experience.first.keys()}\")\n",
    "print(f\"experience keys: {batch.experience.second.keys()}\")\n",
    "print(f\"obs shape: {batch.experience.first['obs'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deeb97d",
   "metadata": {},
   "source": [
    "By inspecting the buffer state we see that it contains:\n",
    "\n",
    " -  `priority_state` which is the state of the sum-tree which is the data structure we use to store the priorities. The sum-tree allows for sampling and priority adjustments with `O(log N)` complexity where `N` is the max length of the buffer. We refer to the [Prioritized Experience Replay Paper](https://arxiv.org/abs/1511.05952), [Dopamine sum_tree.py code](https://github.com/google/dopamine/blob/master/dopamine/replay_memory/sum_tree.py) and [this blog](http://www.sefidian.com/2021/09/09/sumtree-data-structure-for-prioritized-experience-replay-per-explained-with-python-code/) as resources for understanding how the sum-tree works.\n",
    "\n",
    " -  `experience` which is a pytree matching the structure of `fake_timestep` but with an extra axis of `add_batch_size` and `max_length//add_batch_size`.\n",
    "\n",
    " -  a current index that keeps track of where in the buffer experience should be added.\n",
    "\n",
    " -  a `is_full` boolean array which notes if the buffer has been filled above the `max_length//add_batch_size`, after which new added experience starts overwriting old experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093ee971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['experience', 'current_index', 'is_full', 'priority_state'])\n",
      "dict_keys(['obs', 'reward'])\n",
      "(6, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "print(state.__dict__.keys())\n",
    "print(state.experience.keys())\n",
    "print(state.experience['obs'].shape) # prints (6, 5, 2) = (max_length, *fake_timestep['obs'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
