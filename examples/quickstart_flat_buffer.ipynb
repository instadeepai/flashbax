{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c803a85b",
   "metadata": {},
   "source": [
    "# Quickstart: Using the Flat Buffer with Flashbax\n",
    "\n",
    "This guide demonstrates how to use the Flat Buffer, for experience replay in reinforcement learning tasks. The Flat Buffer operates by saving all experience data in a first-in-first-out (FIFO) queue and returns batches of uniformly sampled experience from it. This is akin to the buffer used in the [original DQN paper](https://arxiv.org/abs/1312.5602). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15752f",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "If running locally as a dev then uncomment the below 2 lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536ced4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import sys\n",
    "# sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2caa3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chex\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Setup fake devices - we use this later with `jax.pmap`.\n",
    "DEVICE_COUNT_MOCK = 2\n",
    "chex.set_n_cpu_devices(DEVICE_COUNT_MOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c8a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import flashbax as fbx\n",
    "except ModuleNotFoundError:\n",
    "    print('installing flashbax')\n",
    "    %pip install -q flashbax\n",
    "    import flashbax as fbx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825b9dec",
   "metadata": {},
   "source": [
    "### Initialize the Flat Buffer\n",
    "\n",
    "The following code demonstrates how to initialize the Flat Buffer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285ec603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e.toledo/flashbax/flashbax/buffers/trajectory_buffer.py:473: UserWarning: Setting max_size dynamically sets the `max_length_time_axis` to be `max_size`//`add_batch_size = 5`.This allows one to control exactly how many transitions are stored in the buffer.Note that this overrides the `max_length_time_axis` argument.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# First define hyper-parameters of the buffer.\n",
    "max_length = 32 # Maximum length of buffer (max number of experiences stored within the state).\n",
    "min_length = 8 # Minimum number of experiences saved in the buffer state before we can sample.\n",
    "sample_batch_size = 4 # Batch size of experience data sampled from the buffer.\n",
    "\n",
    "add_sequences = False # Will we be adding data in sequences to the buffer?\n",
    "add_batch_size = 6    # Will we be adding data in batches to the buffer? \n",
    "                      # It is possible to add data in both sequences and batches. \n",
    "                      # If adding data in batches, what is the batch size that is being added each time?\n",
    "\n",
    "# Instantiate the flat buffer, which is a Dataclass of pure functions.\n",
    "buffer = fbx.make_flat_buffer(max_length, min_length, sample_batch_size, add_sequences, add_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e9d73",
   "metadata": {},
   "source": [
    "## Key Functionality of the Flat Buffer\n",
    "\n",
    "The Flat Buffer provides the following key functions:\n",
    "\n",
    "1. `init`: Initialize the state of the buffer.\n",
    "2. `add`: Add a new batch of experience data to the buffer.\n",
    "3. `can_sample`: Check if the buffer is ready to be sampled.\n",
    "4. `sample`: Sample a batch from the buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3600eeb",
   "metadata": {},
   "source": [
    "## Initialize the Buffer State\n",
    "\n",
    "To demonstrate how to use the buffer, we'll start by initializing its state using the `init` function. This requires a unit of experience data, which is used to infer the structure of the experience that will be added later. For this example, we create a fake timestep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "792578a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1695315515.489560  758745 pjrt_api.cc:98] GetPjrtApi was found for tpu at /home/e.toledo/miniconda3/envs/flashbax/lib/python3.10/site-packages/libtpu/libtpu.so\n",
      "I0000 00:00:1695315515.489634  758745 pjrt_api.cc:67] PJRT_Api is set for device type tpu\n",
      "I0000 00:00:1695315515.489637  758745 pjrt_api.cc:72] PJRT plugin for tpu has PJRT API version 0.30. The framework PJRT API version is 0.30.\n",
      "I0000 00:00:1695315518.435092  758745 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    }
   ],
   "source": [
    "fake_timestep = {\"obs\": jnp.array([5, 4]), \"reward\": jnp.array(1.0)} \n",
    "state = buffer.init(fake_timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b94d1",
   "metadata": {},
   "source": [
    "## Adding Experience to the Buffer\n",
    "To fill the buffer above its minimum length, we use the `add` function. The function expects batches of experience, which we create by stacking timesteps. Note: We have specified that the buffer expects batches of experiences but we can specify that individual timesteps are added each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1614242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_batch = jax.tree.map(lambda x: jnp.stack([x + i for i in range(add_batch_size)]), fake_timestep)\n",
    "state = buffer.add(state, fake_batch)\n",
    "assert not buffer.can_sample(state)  # Buffer is not ready to sample\n",
    "state = buffer.add(state, fake_batch)\n",
    "assert buffer.can_sample(state)  # Buffer is now ready to sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df2f0f",
   "metadata": {},
   "source": [
    "## Sampling from the Buffer\n",
    "To sample from the buffer, we use the `sample` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6618232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.PRNGKey(0)  # Setup source of randomness\n",
    "batch = buffer.sample(state, rng_key)  # Sample a batch of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c9ca0",
   "metadata": {},
   "source": [
    "By inspecting the batch object, you can see that it is a TransitionSample object. This object contains an ExperiencePair object containing the transition data. The first and second attributes of the ExperiencePair object will match the structure of `fake_timestep` with an added batch dimension and sequence dimension of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cae9cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['obs', 'reward'])\n",
      "dict_keys(['obs', 'reward'])\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print(batch.experience.first.keys()) # prints dict_keys(['obs', 'reward'])\n",
    "print(batch.experience.second.keys()) # prints dict_keys(['obs', 'reward'])\n",
    "print(batch.experience.first['reward'].shape) # prints (4,) = (sample_batch_size, *fake_timestep['reward'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3cab2",
   "metadata": {},
   "source": [
    "## Buffer State and Structure\n",
    "Inspecting the buffer state reveals its structure:\n",
    "\n",
    "- `experience`: A pytree matching the structure of the timestep but with two extra axis of size add_batch_size and max_length//add_batch_size.\n",
    "- `current_index`: Tracks where in the buffer experience should be added.\n",
    "- `is_full`: A boolean array indicating if the buffer has been filled above max_length//add_batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b364a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['experience', 'current_index', 'is_full'])\n",
      "dict_keys(['obs', 'reward'])\n",
      "(6, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "print(state.__dict__.keys()) \n",
    "print(state.experience.keys())\n",
    "print(state.experience['obs'].shape) # prints (6, 5, 2) = (add_batch_size, max_length//add_batch_size, *fake_timestep['obs'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b259dfb1",
   "metadata": {},
   "source": [
    "## Using the Buffer with `jax.pmap`\n",
    "Flashbax buffers can be `jit`-ed and `pmap`-ed. The following code demonstrates how to use the Flat Buffer with `pmap`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "541ce614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/e.toledo/flashbax/flashbax/buffers/trajectory_buffer.py:473: UserWarning: Setting max_size dynamically sets the `max_length_time_axis` to be `max_size`//`add_batch_size = 4`.This allows one to control exactly how many transitions are stored in the buffer.Note that this overrides the `max_length_time_axis` argument.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define a function to create a fake batch of data\n",
    "def get_fake_batch(fake_timestep: chex.ArrayTree, batch_size) -> chex.ArrayTree:\n",
    "    return jax.tree.map(lambda x: jnp.stack([x + i for i in range(batch_size)]), fake_timestep)\n",
    "\n",
    "add_batch_size = 8\n",
    "\n",
    "# Re-instantiate the buffer\n",
    "buffer = fbx.make_flat_buffer(max_length, min_length, sample_batch_size, add_sequences, add_batch_size)\n",
    "\n",
    "# Initialize the buffer's state with a \"device\" dimension\n",
    "fake_timestep_per_device = jax.tree.map(\n",
    "    lambda x: jnp.stack([x + i for i in range(DEVICE_COUNT_MOCK)]), fake_timestep\n",
    ")\n",
    "state = jax.pmap(buffer.init)(fake_timestep_per_device)\n",
    "\n",
    "# Fill the buffer above its minimum length\n",
    "fake_batch = jax.pmap(get_fake_batch, static_broadcasted_argnums=1)(\n",
    "    fake_timestep_per_device, add_batch_size\n",
    ")\n",
    "# Add two timesteps to form one transition pair\n",
    "state = jax.pmap(buffer.add)(state, fake_batch)\n",
    "state = jax.pmap(buffer.add)(state, fake_batch)\n",
    "assert buffer.can_sample(state).all()\n",
    "\n",
    "# Sample from the buffer\n",
    "rng_key_per_device = jax.random.split(rng_key, DEVICE_COUNT_MOCK)\n",
    "batch = jax.pmap(buffer.sample)(state, rng_key_per_device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb20b7",
   "metadata": {},
   "source": [
    "When inspecting the objects, you'll observe an extra leading \"device\" dimension, replicating the buffer behavior across multiple devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b615e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8, 4, 2)\n",
      "(2, 4)\n",
      "[ True  True]\n"
     ]
    }
   ],
   "source": [
    "print(state.experience['obs'].shape) # prints (2, 8, 4 , 2) = (DEVICE_COUNT_MOCK, add_batch_size, max_length//add_batch_size, *fake_timestep['obs'].shape)\n",
    "print(batch.experience.first['reward'].shape) # prints (2, 4,) = (DEVICE_COUNT_MOCK, sample_batch_size, *fake_timestep['reward'].shape)\n",
    "print(buffer.can_sample(state)) # prints [True, True] as the state on each device is full above `min_length`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
