{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c803a85b",
   "metadata": {},
   "source": [
    "# Quickstart: Using the Flat Buffer with Flashbax\n",
    "\n",
    "This guide demonstrates how to use the N-Step Buffer, for experience replay in reinforcement learning tasks. The N-Step Buffer operates by saving all experience data in a first-in-first-out (FIFO) queue and returns batches of uniformly sampled experience from it. This is akin to the buffer used in the [original DQN paper](https://arxiv.org/abs/1312.5602) when using an n-step of 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15752f",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "If running locally as a dev then uncomment the below 2 lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ced4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa3477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chex\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Setup fake devices - we use this later with `jax.pmap`.\n",
    "DEVICE_COUNT_MOCK = 2\n",
    "chex.set_n_cpu_devices(DEVICE_COUNT_MOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c8a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import flashbax as fbx\n",
    "except ModuleNotFoundError:\n",
    "    print('installing flashbax')\n",
    "    %pip install -q flashbax\n",
    "    import flashbax as fbx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825b9dec",
   "metadata": {},
   "source": [
    "### Initialize the N-Step Buffer\n",
    "\n",
    "The following code demonstrates how to initialize the N-Step Buffer. For this section we will use an n-step of 1 to keep things simple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ec603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define hyper-parameters of the buffer.\n",
    "max_length = (\n",
    "    32  # Maximum length of buffer (max number of experiences stored within the state).\n",
    ")\n",
    "min_length = (\n",
    "    8  # Minimum number of experiences saved in the buffer state before we can sample.\n",
    ")\n",
    "sample_batch_size = 4  # Batch size of experience data sampled from the buffer.\n",
    "\n",
    "add_sequences = False  # Will we be adding data in sequences to the buffer?\n",
    "add_batch_size = 6  # Will we be adding data in batches to the buffer?\n",
    "# It is possible to add data in both sequences and batches.\n",
    "# If adding data in batches, what is the batch size that is being added each time?\n",
    "\n",
    "# Instantiate the flat buffer, which is a Dataclass of pure functions.\n",
    "buffer = fbx.make_n_step_buffer(\n",
    "    max_length=max_length,\n",
    "    min_length=min_length,\n",
    "    sample_batch_size=sample_batch_size,\n",
    "    add_sequences=add_sequences,\n",
    "    add_batch_size=add_batch_size,\n",
    "    n_step=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e9d73",
   "metadata": {},
   "source": [
    "## Key Functionality of the Flat Buffer\n",
    "\n",
    "The Flat Buffer provides the following key functions:\n",
    "\n",
    "1. `init`: Initialize the state of the buffer.\n",
    "2. `add`: Add a new batch of experience data to the buffer.\n",
    "3. `can_sample`: Check if the buffer is ready to be sampled.\n",
    "4. `sample`: Sample a batch from the buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3600eeb",
   "metadata": {},
   "source": [
    "## Initialize the Buffer State\n",
    "\n",
    "To demonstrate how to use the buffer, we'll start by initializing its state using the `init` function. This requires a unit of experience data, which is used to infer the structure of the experience that will be added later. For this example, we create a fake timestep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792578a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_timestep = {\"obs\": jnp.array([5, 4]), \"reward\": jnp.array(1.0)}\n",
    "state = buffer.init(fake_timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b94d1",
   "metadata": {},
   "source": [
    "## Adding Experience to the Buffer\n",
    "To fill the buffer above its minimum length, we use the `add` function. The function expects batches of experience, which we create by stacking timesteps. Note: We have specified that the buffer expects batches of experiences but we can specify that individual timesteps are added each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_batch = jax.tree_map(\n",
    "    lambda x: jnp.stack([x + i for i in range(add_batch_size)]), fake_timestep\n",
    ")\n",
    "state = buffer.add(state, fake_batch)\n",
    "assert not buffer.can_sample(state)  # Buffer is not ready to sample\n",
    "state = buffer.add(state, fake_batch)\n",
    "assert buffer.can_sample(state)  # Buffer is now ready to sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3df2f0f",
   "metadata": {},
   "source": [
    "## Sampling from the Buffer\n",
    "To sample from the buffer, we use the `sample` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.PRNGKey(0)  # Setup source of randomness\n",
    "batch = buffer.sample(state, rng_key)  # Sample a batch of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c9ca0",
   "metadata": {},
   "source": [
    "By inspecting the batch object, you can see that it is a TransitionSample object. This object contains an ExperiencePair object containing the transition data. The first and second attributes of the ExperiencePair object will match the structure of `fake_timestep` with an added batch dimension and sequence dimension of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae9cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch.experience.first.keys())  # prints dict_keys(['obs', 'reward'])\n",
    "print(batch.experience.second.keys())  # prints dict_keys(['obs', 'reward'])\n",
    "print(\n",
    "    batch.experience.first[\"reward\"].shape\n",
    ")  # prints (4,) = (sample_batch_size, *fake_timestep['reward'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3cab2",
   "metadata": {},
   "source": [
    "## Buffer State and Structure\n",
    "Inspecting the buffer state reveals its structure:\n",
    "\n",
    "- `experience`: A pytree matching the structure of the timestep but with two extra axis of size add_batch_size and max_length//add_batch_size.\n",
    "- `current_index`: Tracks where in the buffer experience should be added.\n",
    "- `is_full`: A boolean array indicating if the buffer has been filled above max_length//add_batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b364a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state.__dict__.keys())\n",
    "print(state.experience.keys())\n",
    "print(\n",
    "    state.experience[\"obs\"].shape\n",
    ")  # prints (6, 5, 2) = (add_batch_size, max_length//add_batch_size, *fake_timestep['obs'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b259dfb1",
   "metadata": {},
   "source": [
    "## Using the Buffer with `jax.pmap`\n",
    "Flashbax buffers can be `jit`-ed and `pmap`-ed. The following code demonstrates how to use the Flat Buffer with `pmap`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ce614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a fake batch of data\n",
    "def get_fake_batch(fake_timestep: chex.ArrayTree, batch_size) -> chex.ArrayTree:\n",
    "    return jax.tree_map(\n",
    "        lambda x: jnp.stack([x + i for i in range(batch_size)]), fake_timestep\n",
    "    )\n",
    "\n",
    "\n",
    "add_batch_size = 8\n",
    "\n",
    "# Re-instantiate the buffer\n",
    "buffer = fbx.make_n_step_buffer(\n",
    "    max_length=max_length,\n",
    "    min_length=min_length,\n",
    "    sample_batch_size=sample_batch_size,\n",
    "    add_sequences=add_sequences,\n",
    "    add_batch_size=add_batch_size,\n",
    "    n_step=1,\n",
    ")\n",
    "\n",
    "# Initialize the buffer's state with a \"device\" dimension\n",
    "fake_timestep_per_device = jax.tree_map(\n",
    "    lambda x: jnp.stack([x + i for i in range(DEVICE_COUNT_MOCK)]), fake_timestep\n",
    ")\n",
    "state = jax.pmap(buffer.init)(fake_timestep_per_device)\n",
    "\n",
    "# Fill the buffer above its minimum length\n",
    "fake_batch = jax.pmap(get_fake_batch, static_broadcasted_argnums=1)(\n",
    "    fake_timestep_per_device, add_batch_size\n",
    ")\n",
    "# Add two timesteps to form one transition pair\n",
    "state = jax.pmap(buffer.add)(state, fake_batch)\n",
    "state = jax.pmap(buffer.add)(state, fake_batch)\n",
    "assert buffer.can_sample(state).all()\n",
    "\n",
    "# Sample from the buffer\n",
    "rng_key_per_device = jax.random.split(rng_key, DEVICE_COUNT_MOCK)\n",
    "batch = jax.pmap(buffer.sample)(state, rng_key_per_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb20b7",
   "metadata": {},
   "source": [
    "When inspecting the objects, you'll observe an extra leading \"device\" dimension, replicating the buffer behavior across multiple devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b615e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    state.experience[\"obs\"].shape\n",
    ")  # prints (2, 8, 4 , 2) = (DEVICE_COUNT_MOCK, add_batch_size, max_length//add_batch_size, *fake_timestep['obs'].shape)\n",
    "print(\n",
    "    batch.experience.first[\"reward\"].shape\n",
    ")  # prints (2, 4,) = (DEVICE_COUNT_MOCK, sample_batch_size, *fake_timestep['reward'].shape)\n",
    "print(\n",
    "    buffer.can_sample(state)\n",
    ")  # prints [True, True] as the state on each device is full above `min_length`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1561f1",
   "metadata": {},
   "source": [
    "## N-step > 1\n",
    "\n",
    "We will now demonstrate how to use n-step buffers greater than 1.\n",
    "\n",
    "First lets simplify the set up to deal with only a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b94878",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step = 3\n",
    "add_batch_size = 1\n",
    "add_sequence_size = 12\n",
    "max_length = 64\n",
    "sample_batch_size = 4\n",
    "add_sequences = True\n",
    "gamma = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea3cf4",
   "metadata": {},
   "source": [
    "Then we need to create our n step buffer with an n step greater than 1. This is where we need to specify if we wish to have sequence mapping functions. For this example we are going to use our utility functions to produce n step returns. \n",
    "\n",
    "We first need to create our attribute-to-function map as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d12690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flashbax.buffers import n_step_buffer\n",
    "\n",
    "returns_fun = lambda x, y: jax.vmap(n_step_buffer.n_step_returns, in_axes=(0, 0, None))(\n",
    "    x, y, n_step\n",
    ")\n",
    "discount_fun = lambda x: jax.vmap(n_step_buffer.n_step_product, in_axes=(0, None))(\n",
    "    x, n_step\n",
    ")\n",
    "n_step_functional_map = {\n",
    "    (\"reward\", \"reward\", \"discount\"): returns_fun,\n",
    "    (\"discount\", \"discount\"): discount_fun,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6face",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = fbx.make_n_step_buffer(\n",
    "    max_length=max_length,\n",
    "    min_length=min_length,\n",
    "    sample_batch_size=sample_batch_size,\n",
    "    add_sequences=add_sequences,\n",
    "    add_batch_size=add_batch_size,\n",
    "    n_step=n_step,\n",
    "    n_step_functional_map=n_step_functional_map,\n",
    ")\n",
    "\n",
    "fake_timestep = {\n",
    "    \"obs\": jnp.array([5, 4]),\n",
    "    \"reward\": jnp.array(1.0),\n",
    "    \"discount\": jnp.array(1.0),\n",
    "}\n",
    "\n",
    "buffer_state = buffer.init(fake_timestep)\n",
    "\n",
    "fake_batch_sequence = jax.tree_map(\n",
    "    lambda x: jnp.stack([x for i in range(add_batch_size)])[:, jnp.newaxis].repeat(\n",
    "        add_sequence_size, axis=1\n",
    "    ),\n",
    "    fake_timestep,\n",
    ")\n",
    "\n",
    "fake_batch_sequence[\"discount\"] = fake_batch_sequence[\"discount\"].at[0,2].set(0) #* gamma\n",
    "fake_batch_sequence[\"reward\"] = fake_batch_sequence[\"reward\"] + jnp.arange(add_sequence_size)\n",
    "\n",
    "buffer_state = buffer.add(buffer_state, fake_batch_sequence)\n",
    "\n",
    "rng_key = jax.random.PRNGKey(2)\n",
    "\n",
    "sampled_batch = buffer.sample(buffer_state, rng_key)\n",
    "\n",
    "print(\"The Reward Sequence added:\",fake_batch_sequence[\"reward\"])\n",
    "print(\"The Discount Sequence added:\",fake_batch_sequence[\"discount\"])\n",
    "\n",
    "print(\"The n-step return of the sampled data:\", sampled_batch.experience.first[\"reward\"])\n",
    "print(\"The reward after n steps (but not included in) of the sampled data:\", sampled_batch.experience.second[\"reward\"])\n",
    "print(\"The n-step discount of the sampled data:\", sampled_batch.experience.first[\"discount\"])\n",
    "print(\"The discount after n steps (but not included in) of the sampled data:\", sampled_batch.experience.second[\"discount\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6599fd",
   "metadata": {},
   "source": [
    "Lets analyse the above result. We can use the reward value after n steps to know which sequence was sampled. For the first item in the batch, the reward after n steps is 5. This means the reward sequence sampled was [ 2.  3.  4.  5.]. Additionally, the discount sequence sampled was [1. 0. 1. 1.]. In this case let us manually calculate what the 3-step reward should be for the first position. we have 2 + 1.0*(3 + 0.0*(4)) = 5. We see this result in the n-step return values given by the experience tuple. Additionally, we use the product of n-step discounts to know whether or not we reached a discount at some point during the n-step calculation so that we can accurately identify if we need to use a bootstrap value or not for training. We see that our discount value is zero which is correct. The values present in the .second transition give us access to information that occurs after the n-step transition i.e. the reward after the n-step transition that is not included in the n-steps. This would be how we would access the observation we would use for bootstrapping or other information such as the future action for a SARSA-like agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
